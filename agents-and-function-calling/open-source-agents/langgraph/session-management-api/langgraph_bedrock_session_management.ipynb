{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Assistant Bot with LangGraph and Bedrock Session Management\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to build a sales assistant bot using LangGraph, a powerful framework for creating stateful, multi-step conversational AI applications. The example focuses on a shoe shopping assistant that helps users find their perfect pair of shoes through an interactive conversation.\n",
    "\n",
    "Key features demonstrated in this notebook:\n",
    "\n",
    "1. **LangGraph Integration**: Shows how to use LangGraph with Amazon Bedrock to create a conversation flow with multiple steps and tools.\n",
    "\n",
    "2. **Amazon Bedrock Session Management**: Implements state persistence using Bedrock, allowing the bot to maintain context and resume conversations where they left off.\n",
    "\n",
    "3. **Stateful Conversations**: Demonstrates how to maintain user preferences and conversation history across multiple interactions.\n",
    "\n",
    "4. **Real-world Use Case**: Implements a practical shoe shopping assistant that:\n",
    "   - Asks relevant questions about user preferences\n",
    "   - Provides personalized recommendations\n",
    "   - Maintains context throughout the shopping experience\n",
    "\n",
    "This example serves as a template for developers looking to build sophisticated conversational applications with state management capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "Let's start with installing required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U langgraph_checkpoint_aws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create Bedrock client that is used to configure LLM in LangChain to use Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_checkpoint_aws.saver import BedrockSessionSaver\n",
    "import boto3\n",
    "\n",
    "# ---- ⚠️ Update region for your AWS setup ⚠️ ----\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To integrate LLM from Amazon Bedrock, we are going to use ChatBedrockConverse class of LangChain. We also need to use bedrock_client to connect to Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    # model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "This section contains the custom tools and utilities needed for our sales assistant bot. These tools handle various functionalities such as searching for shoes, managing user preferences, and processing orders. \n",
    "\n",
    "The tools are designed to be modular and reusable, making it easy to extend or modify the bot's capabilities. Each tool follows a consistent interface pattern, accepting specific inputs and returning structured outputs that can be used in the conversation flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_shoes(preference):\n",
    "    \"\"\"\n",
    "    Search for shoes based on user preferences and interests.\n",
    "    This tool helps find shoes that match specific activities or styles like running, hiking, casual wear, or basketball.\n",
    "\n",
    "    Args:\n",
    "    preference(str): User preference\n",
    "\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(\"shoe_store.db\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Search in category and features\n",
    "    query = \"\"\"\n",
    "    SELECT * FROM shoes \n",
    "    WHERE LOWER(category) LIKE LOWER(?) \n",
    "    OR LOWER(features) LIKE LOWER(?)\n",
    "    \"\"\"\n",
    "    search_term = f\"%{preference}%\"\n",
    "    cursor.execute(query, (search_term, search_term))\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "@tool\n",
    "def add_to_cart(\n",
    "    user_id,\n",
    "    shoe_id,\n",
    "    size,\n",
    "    quantity=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Add to cart\n",
    "    This tool helps user to add shoes to the cart\n",
    "\n",
    "    Args:\n",
    "    user_id(int): User id\n",
    "    shoe_id(int): Shoe id\n",
    "    size(str): Shoe size\n",
    "    quantity(int, optional): Quantity\n",
    "    size()\n",
    "\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(\"shoe_store.db\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Check if shoe exists and has enough stock\n",
    "        cursor.execute(\"SELECT stock FROM shoes WHERE id = ?\", (shoe_id,))\n",
    "        result = cursor.fetchone()\n",
    "        if not result:\n",
    "            conn.close()\n",
    "            return False, \"Shoe not found\"\n",
    "\n",
    "        current_stock = result[0]\n",
    "        if current_stock < quantity:\n",
    "            conn.close()\n",
    "            return False, f\"Not enough stock. Available: {current_stock}\"\n",
    "\n",
    "        # Check if item already in cart\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "        SELECT id, quantity FROM shopping_cart \n",
    "        WHERE user_id = ? AND shoe_id = ? AND size = ?\n",
    "        \"\"\",\n",
    "            (user_id, shoe_id, size),\n",
    "        )\n",
    "        cart_item = cursor.fetchone()\n",
    "\n",
    "        added_at = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") \n",
    "\n",
    "        if cart_item:\n",
    "            # Update existing cart item\n",
    "            new_quantity = cart_item[1] + quantity\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "            UPDATE shopping_cart \n",
    "            SET quantity = ?, added_at = ?\n",
    "            WHERE id = ?\n",
    "            \"\"\",\n",
    "                (new_quantity, added_at, cart_item[0]),\n",
    "            )\n",
    "        else:\n",
    "            # Add new cart item\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "            INSERT INTO shopping_cart (user_id, shoe_id, quantity, size, added_at)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "            \"\"\",\n",
    "                (user_id, shoe_id, quantity, size, added_at),\n",
    "            )\n",
    "\n",
    "        # Update shoe stock\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "        UPDATE shoes \n",
    "        SET stock = stock - ? \n",
    "        WHERE id = ?\n",
    "        \"\"\",\n",
    "            (quantity, shoe_id),\n",
    "        )\n",
    "\n",
    "        conn.commit()\n",
    "        return True, \"Item added to cart successfully\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return False, f\"Error adding to cart: {str(e)}\"\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_shoes, add_to_cart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Setup and Prompt Configuration\n",
    "\n",
    "This section sets up the core components of our LangGraph chatbot. We define the state management structure and configure the primary conversation prompt. Key elements include:\n",
    "\n",
    "- State definition for managing conversation messages\n",
    "- Graph initialization using StateGraph\n",
    "- Configuration of the primary assistant prompt that defines the bot's personality and purpose\n",
    "- Integration of the language model with custom tools for enhanced functionality\n",
    "\n",
    "The prompt is designed to create a friendly shopping assistant that guides users through the shoe purchasing process by asking relevant questions about their preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "\n",
    "primary_assistant_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful and friendly chatbot who can help users to purchase shoes. \"\n",
    "             \"Ask questions about user preferences and interests \"\n",
    "             \"Ask questions that can help user to add shoes to the cart \"\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "runnable_with_tools = primary_assistant_prompt | llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [runnable_with_tools.invoke(state)]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    "    {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section defines the basic flow of our conversation graph by establishing the connections between different components. The graph is constructed with two simple edges:\n",
    "1. From START to the chatbot\n",
    "2. From tools to the chatbot\n",
    "\n",
    "> **Important Note**: At this stage, the graph operates without any persistent memory. This means that each conversation starts fresh, without any knowledge of previous interactions. In the following sections, we'll enhance this basic structure by adding session management capabilities using Bedrock to maintain conversation state across interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section implements a simple interactive conversation loop that allows users to chat with our sales assistant. The loop continues until the user types 'quit', 'exit', or 'q' to end the conversation.\n",
    "\n",
    "> **Important Limitation**: In this basic implementation, each time a user starts a new conversation (by running this cell again), all previous conversation history is lost. The bot has no memory of past interactions, preferences, or context from previous conversations. This means:\n",
    "> - Every conversation starts fresh\n",
    "> - Previously discussed preferences need to be repeated\n",
    "> - Shopping cart information is not preserved\n",
    "> \n",
    "> We'll address this limitation in the next section by implementing session management with Bedrock to maintain conversation state across sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        print(event)\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph_checkpoint_aws.saver import BedrockSessionSaver\n",
    "\n",
    "session_saver = BedrockSessionSaver(\n",
    "    region_name=\"us-west-2\",\n",
    ")\n",
    "graph = graph_builder.compile(checkpointer=session_saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = session_saver.session_client.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = client.create_session()[\"sessionId\"]\n",
    "print(\"Using SessionId:\", session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": session_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}, config):\n",
    "        for value in event.values():\n",
    "            if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "                print(\"Assistant:\", value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in graph.get_state_history(config, limit=3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replaying\n",
    "\n",
    "Replaying allows us to revisit and reproduce an agent's past actions, up to and including a specific step (checkpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_checkpoints = []\n",
    "for state in graph.get_state_history(config):\n",
    "    all_checkpoints.append(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph replays previously executed steps before the provided `checkpoint_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_replay = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": session_id,\n",
    "        \"checkpoint_id\": \"1effd9d7-97bb-67e4-8002-58cd344c5c6f\",\n",
    "    }\n",
    "}\n",
    "for event in graph.stream(None, config_replay, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forking\n",
    "\n",
    "Forking allows you to revisit an agent's past actions and explore alternative paths within the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": session_id,\n",
    "        \"checkpoint_id\": \"1effd9d7-97bb-67e4-8002-58cd344c5c6f\",\n",
    "    }\n",
    "}\n",
    "graph.update_state(config, {\"state\": \"updated state\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": session_id,\n",
    "        \"checkpoint_id\": \"1effd9ff-2e06-65ce-8003-3c2c344e1971\",\n",
    "    }\n",
    "}\n",
    "for event in graph.stream(None, config, stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human in the loop\n",
    "\n",
    "HIL interaction pattern, allows the graph to stop at specific steps and seek human approval before proceeding. This is important if we have to review specific tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Literal\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "def human_review_node(state) -> Command[Literal[\"call_llm\", \"run_tool\"]]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    tool_call = last_message.tool_calls[-1]\n",
    "\n",
    "    # this is the value we'll be providing via Command(resume=<human_review>)\n",
    "    human_review = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            # Surface tool calls for review\n",
    "            \"tool_call\": tool_call,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    review_action = human_review[\"action\"]\n",
    "    review_data = human_review.get(\"data\")\n",
    "\n",
    "    # if approved, call the tool\n",
    "    if review_action == \"continue\":\n",
    "        return Command(goto=\"run_tool\")\n",
    "\n",
    "    # update the AI message AND call tools\n",
    "    elif review_action == \"update\":\n",
    "        updated_message = {\n",
    "            \"role\": \"ai\",\n",
    "            \"content\": last_message.content,\n",
    "            \"tool_calls\": [\n",
    "                {\n",
    "                    \"id\": tool_call[\"id\"],\n",
    "                    \"name\": tool_call[\"name\"],\n",
    "                    # This the update provided by the human\n",
    "                    \"args\": review_data,\n",
    "                }\n",
    "            ],\n",
    "            # This is important - this needs to be the same as the message you replacing!\n",
    "            # Otherwise, it will show up as a separate message\n",
    "            \"id\": last_message.id,\n",
    "        }\n",
    "        return Command(goto=\"run_tool\", update={\"messages\": [updated_message]})\n",
    "\n",
    "    # provide feedback to LLM\n",
    "    elif review_action == \"feedback\":\n",
    "        # NOTE: we're adding feedback message as a ToolMessage\n",
    "        # to preserve the correct order in the message history\n",
    "        # (AI messages with tool calls need to be followed by tool call messages)\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            # This is our natural language feedback\n",
    "            \"content\": review_data,\n",
    "            \"name\": tool_call[\"name\"],\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "        }\n",
    "        return Command(goto=\"call_llm\", update={\"messages\": [tool_message]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tool(state):\n",
    "    new_messages = []\n",
    "    tools = {\"search_shoes\": search_shoes, \"add_to_cart\": add_to_cart}\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    for tool_call in tool_calls:\n",
    "        tool = tools[tool_call[\"name\"]]\n",
    "        result = tool.invoke(tool_call[\"args\"])\n",
    "        new_messages.append(\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": tool_call[\"name\"],\n",
    "                \"content\": result,\n",
    "                \"tool_call_id\": tool_call[\"id\"],\n",
    "            }\n",
    "        )\n",
    "    return {\"messages\": new_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def route_after_llm(state) -> Literal[END, \"human_review_node\"]:\n",
    "    if len(state[\"messages\"][-1].tool_calls) == 0:\n",
    "        return END\n",
    "    else:\n",
    "        return \"human_review_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"run_tool\", run_tool)\n",
    "graph_builder.add_node(\"human_review_node\", human_review_node)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_conditional_edges(\"chatbot\", route_after_llm)\n",
    "graph_builder.add_edge(\"run_tool\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_saver = BedrockSessionSaver(\n",
    "    region_name=\"us-west-2\",\n",
    ")\n",
    "graph = graph_builder.compile(checkpointer=session_saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = client.create_session()[\"sessionId\"]\n",
    "print(\"Using SessionId:\", session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_input = {\"messages\": [{\"role\": \"user\", \"content\": \"Can you help me buy running shoes\"}]}\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": session_id}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(\n",
    "    # provide value\n",
    "    Command(resume={\"action\": \"continue\"}),\n",
    "    thread,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
